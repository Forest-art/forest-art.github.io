<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Yue Ma, Ma Yue, THU, Tsinghua University"> 
<meta name="description" content="MaYue's Home">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>ShawnLou@HKUST</title>
<style>
    .smaller-image {
      width: 20%;
    }
</style>


</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/mayuelala" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Xiaocheng (Shawn) Lu </h1>
					<!-- <h1></h1> -->
					<!-- <img src="indexpics/sign.png" alt="ä½ çš„å›¾ç‰‡"  class="smaller-image"> -->
					</div>
				<h3>Phd Student</h3>
				<p>
					The Hong Kong University of Science and Technology <br>
					HongKong.<br>
					<br>
					Email: xiaochenglu1997@gmail.com<br>
					
				</p>
				<p> <a href="https://scholar.google.com/citations?user=S7XO5kIAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/Forest-art"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
				<img src="./pic/luxiaocheng.jpg" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I am a PhD student of CSE at <a href="https://hkust.edu.hk/">The Hong Kong University of Science and Technology (HKUST)</a>, under the supervision of <a href="https://cse.hkust.edu.hk/~songguo/" target="_blank">Prof. Song Guo (IEEE Fellow)</a>. 
	Currently, I am also a research intern at Shanghai AILab, supervised by <a href="http://leibai.site/">Dr. Lei Bai</a>. 
</p>
<p>
	Before that, I obtained my M.S. degree in Computer Science at Northwestern Polytechnical University <a href="https://www.nwpu.edu.cn/">NWPU</a>, supervised by <a href="https://crabwq.github.io/">Qi Wang</a>, <a href="http://iopen.nwpu.edu.cn/info/1015/1389.htm">Yuan Yuan</a> and <a href="https://scholar.google.com/citations?user=ahUibskAAAAJ">Xuelong Li</a> professors. Also, I received my B.Eng degree at the School of Automation, Northwestern Polytechnical University (NWPU). During this period, my research areas included computer vision, image/video enhancement learning, scene text recognition, etc.
</p>
<p>
	Recently, my research interests include Generative Models (Transformer/Diffusion/Flow), AI for Science, AIGC, MultiModal Large Language Models and Zero/Few-shot Learning. 
</p>

<p><i style="color: red; display: inline;">If you are interested in these topics, please feel free to e-mail me. Thanks a lot!</i></p>


<h2>News</h2>
<div style="height: 240px; overflow: auto;">
<ul>
	<li>
		[01/2024] Two papers are accepted by IJCAI 2024!
	</li>
	<li>
		[10/2023] Now I move to Shanghai AiLab as an intern for Ai4Earth.
	</li>
	<li>
		[02/2023] Two papers are accepted by CVPR 2023!
	</li>
	<li>
		[01/2024] A repo for the CZSL paper list has been released; welcome to follow.
	</li>
	<li>
		[12/2022] One paper is accepted by AAAI 2023!
	</li>
	<li>
		[11/2022] The code for DFSP has been released.  
	</li>
	<li>
		[02/2022] One paper is accepted by T-PAMI!
	</li>
	<li>
		[05/2021] One paper is accepted by ICMR 2021!
	</li>
</ul>
</div>

<h2>Industrial Experience</h2>
<table id="tbPublications" width="100%">
	<tbody>
	<p></p>
	</td>
	<tr>
	<tr>
		<td width="306">
		<img src="./industrial/shanghaiailab.jpg" width="255px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b> Shanghai AILab</b></p>
		<p>Oct. 2023 - Present, Shanghai AILab, Shanghai, China </p>
		<p>worked with <a href="http://leibai.site/" target="_blank">Dr. Lei Bai</a> as an Intern</p>
		<em>Topic: AI for Science and Generation </em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./industrial/polyu.png" width="255px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b> The Hong Kong Polytechnic University</b></p>
		<p>Jan. 2023 - Aug. 2023, <a href="https://peilab.netlify.app/" target="_blank">PEILab</a>, Hong Kong, China </p>
		<p>worked with <a href="https://cse.hkust.edu.hk/~songguo/" target="_blank">Prof. Song Guo</a> as a Research Assistant</p>
		<em>Topic: Zero/Few-Shot Learning </em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./industrial/tencent.png" width="255x" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b> Tencent AI Lab</b></p>
		<p>May. 2021 - Aug. 2021, Tencent, CSIG, Beijing, China </p>
		<em>Topic: Cloud Computing</em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
</tbody></table>


<!-- The University of Sydney, Australia

Doctor of Philosophy (Ph.D.) Candidate in Computer Science
Team: Multimedia Laboratory, Sydney (MMLab@Sydney)
 Prof. Wanli Ouyang, Prof. Chang Xu
2022 - Present -->



<h2>Education & Visiting</h2>
<table id="tbPublications" width="100%">
	<tbody>
		<td width="306">
		<img src="./education/hkust.png" width="270px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b>The Hong Kong University of Science and Technology, Hong Kong</b></p>
		<p>PhD Student in Parvasive Intelligence Lab, HKUST </p>
		<p>Advisor: <a href="https://cse.hkust.edu.hk/~songguo/">Prof. Song Guo</a> </p>
		<p>Spring. 2024 - Future <p>
		</p>
		</td>
	</tr>
	<!--########################-->
		<p></p>
	</td>
	<tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./education/siat.png" width="285px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b> University of Chinese Academy of Sciences, China</b></p>
		<p>Research Assistant in Multimedia Laboratory, SIAT, CAS (<a href="https://mmlab.siat.ac.cn/">MMLab@SIAT</a>) </p>
		<p>Advisor: <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=gFtI-8QAAAAJ&view_op=list_works&sortby=pubdate">Prof. Yu Qiao</a> and  <a href="https://scholar.google.com.hk/citations?user=hD948dkAAAAJ&hl=zh-CN">Dr. Yali Wang</a></p>
		<p>Jul. 2021 - Apr. 2022 <p>
		</p>
		</td>
	</tr>
</tbody></table>

<h2> Selected Publications | <a href="https://scholar.google.com/citations?user=S7XO5kIAAAAJ&hl=en">Full List</a></h2>
<!--
<div style="height: 1440px; overflow: auto;">
-->
<table id="tbPublications" width="100%">
	<tbody>
	<td><b>/*Preprints*/</b>
	<p></p>
	</td>
	<tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-cove.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>COVE: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing</b></p>
		<p>Jiangshan Wang*, <b>Yue Ma*</b>, Jiayi Guo*, Yicheng Xiao, Gao Huang, Xiu Li</p>
		<em>arXiv preprint:2406.08850. 2024</em>
		<p> [<a href="https://arxiv.org/abs/2406.08850">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://cove-video.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-followyouremoji.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation</b></p>
		<p><b>Yue Ma</b>, Hongyu Liu, Hongfa Wang, Heng Pan, Yingqing He, Junkun Yuan, Ailing Zeng, Chengfei Cai, Heung-Yeung Shum, Wei Liu, Qifeng Chen</p>
		<em>arXiv preprint:2406.01900. 2024</em>
		<p> [<a href="https://arxiv.org/abs/2406.01900">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://follow-your-emoji.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
			<td width="306">
			<img src="./indexpics/2024-multiBooth.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>MultiBooth: Towards Generating All Your Concepts in an Image from Text</b></p>
			<p>Chenyang Zhu, Kai Li, <b>Yue Ma</b>, Chunming He, Xiu Li</p>
			<em>arXiv preprint:2404.14239. 2024</em>
			<p> [<a href="hhttps://arxiv.org/abs/2404.14239">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://github.com/mayuelala">project page</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-followyourclick.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts</b></p>
		<p><b>Yue Ma</b>, Yingqing He, Hongfa Wang, Andong Wang, Chenyang Qi, Chengfei Cai, Xiu Li, Zhifeng Li, Heung-Yeung Shum, Wei Liu, Qifeng Chen</p>
		<em>arXiv preprint:2403.08268. 2024</em>
		<p> [<a href="https://arxiv.org/abs/2403.08268">paper</a>] [<a href="https://github.com/mayuelala/FollowYourClick">code</a>] [<a href="https://follow-your-click.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2023-MagicStick.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>MagicStickðŸª„: Controllable Video Editing via Control Handle Transformations</b></p>
		<p><b>Yue Ma</b>, Xiaodong Cun, Yingqing He, Chenyang Qi, Xintao Wang, Ying Shan, Xiu Li, Qifeng Chen</p>
		<em>arXiv preprint:2312.03047. 2023</em>
		<p> [<a href="https://arxiv.org/abs/2312.03047">paper</a>] [<a href="https://github.com/mayuelala/MagicStick">code</a>] [<a href="https://magic-stick-edit.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2022-simvtp-framework.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SimVTP: Simple Video Text Pre-training with Masked Autoencoders</b></p>
		<p><b>Yue Ma</b>, Tianyu Yang, Ying Shan, Xiu Li</p>
		<em>arXiv preprint:2211.03490. 2022</em>
		<p> [<a href="https://arxiv.org/pdf/2211.03490">paper</a>] [<a href="https://github.com/mayuelala/SimVTP">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->

	<td><b>/*Journal*/</b>
		<p></p>
		</td>
		
		<tr>
			<td width="306">
			<img src="./indexpics/2023-TMM-mmlab.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>Attentive Snippet Prompting for Video Retrieval</b></p>
			<p>Siran Chen, Qinglin Xu, <b>Yue Ma</b>, Yu Qiao, Yali Wang</p>
			<em>IEEE Transactions on Multimedia (<b>TMM</b>), 2024. </em>
			<i></i>
			<p> [<a href="https://ieeexplore.ieee.org/abstract/document/10268993/">paper</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/10268993/">code</a>] </p>
			</td>
		</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>

	<!--########################-->
		
	<td><b>/*Conference*/</b>
	<p></p>
	</td>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2023-bridge.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection</b></p>
		<p>Yicheng Xiao, Zhuoyan Luo, Yong Liu, <b>Yue Ma</b>, Hengwei Bian, Yatai Ji, Yujiu Yang, Xiu Li</p>
		<em>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2311.16464">paper</a>] [<a href="https://github.com/EasonXiao-888/UVCOM">code</a>] [<a href="https://github.com/EasonXiao-888/UVCOM">project page</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2023-iccv-followyourpose.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>ðŸ•ºðŸ•ºðŸ•º Follow-Your-Pose ðŸ’ƒðŸ’ƒðŸ’ƒ: Pose-Guided Text-to-Video Generation using Pose-Free Videos</b></p>
		<p><b>Yue Ma</b>, Yingqing He, Xiaodong Cun, Xintao Wang, Siran Chen, Ying Shan, Xiu Li, Qifeng Chen</p>
		<em>The 38th Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2304.01186">paper</a>] [<a href="https://github.com/mayuelala/FollowYourPose">code</a>] [<a href="https://follow-your-pose.github.io/">project page</a>] 
		<a target="_blank" href ="https://github.com/mayuelala/FollowYourPose"><img alt="GitHub stars" align="right" src="https://img.shields.io/github/stars/mayuelala/FollowYourPose?style=social"></a></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2024-AAAI-MBEV.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>M-BEV: Masked BEV Perception for Robust Autonomous Driving</b></p>
		<p>Siran Chen, <b>Yue Ma</b>, Yu Qiao, Yali Wang</p>
		<em>The 38th Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2304.01186">paper</a>] [<a href="https://github.com/mayuelala/FollowYourPose">code</a>] [<a href="https://follow-your-pose.github.io/">project page</a>] 
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2023-icassp-audio.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SemanticAC: Semantics-Assisted Framework for Audio Classification</b></p>
		<p>Yicheng Xiao*, <b>Yue Ma*</b>, Shuyan Li, Hantao Zhou, Ran Liao, Xiu Li (* equal contribution)</p>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023. </em>
		<i></i>
		<p> [<a href="https://arxiv.org/abs/2302.05940">paper</a>] [<a href="https://github.com/mayuelala">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2022-mm-graph.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Visual Knowledge Graph for Human Action Reasoning in Videos</b></p>
		<p><b>Yue Ma</b>, Yali Wang, Yue Wu, Ziyu Lyu, Siran Chen, Xiu Li, Yu Qiao</p>
		<em>The 30th ACM International Conference on Multimedia. (<b>ACM MM</b>), 2022. </em>
		<i><p style="color: red; display: inline;">(Oral Presentation)</p></i>
		<p> [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548257">paper</a>] [<a href="https://github.com/mayuelala/AKU">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		


</tbody></table>
<!--
</div>
-->




<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> ......</td></tr>
	<tr><td> [03/2022] Outstanding Graduate Student (Top 10%).</td></tr>
	<tr><td> [09/2021] Campus Job Offers: Bytedance, Baidu, Huawei, etc.</td></tr>
	<tr><td> [01/2020] Huawei Cloud Artificial Intelligence Innovation Application Competition (Top 2%).</td></tr>
	<tr><td> [08/2017] National University Student NXP Cup Smart Car Competition National Finals Grand Prize (1st in 300+ teams).</td></tr>
	</tbody>
</table>


<h2>Professional Services</h2>
<ul>
	<li>	
	<b>Student Reviewers:</b><br>
	Computer Vision and Pattern Recognition (CVPR)<br>
	International Conference on Computer Vision (ICCV)<br>
	Conference and Workshop on Neural Information Processing Systems (NeurIPS)<br>
	International Conference on Learning Representations (ICLR) <br>
	AAAI Conference on Artificial Intelligence (AAAI)<br>
	IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
	</li>
</ul>


<h2>Teaching</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2024-2025</td><td>Fall</td><td>COMP2011, Programming with C++</td>
		</tr>
	</tbody>
</table>




<div id="footer">
	<div id="footer-text"></div>
</div>
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=yEsLWkQotJI-9izR4nI_5CTDskeIzF6Zy2u2vreBKK4&cl=ffffff&w=a"></script>
	<p><center> &copy; Shawn Lou </center></p>
</div>
</body></html>
